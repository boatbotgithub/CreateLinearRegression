{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        initilize = 10\n",
    "        random_weigths = np.random.randint(30)\n",
    "        self.history = []\n",
    "        self.weigths_his = []\n",
    "        self.biases_his = []\n",
    "        self.epoch_his = []\n",
    "        self.loss_his = []\n",
    "        \n",
    "        self.weigths = np.random.uniform(-4, 4)#เข้า2 ออก 1\n",
    "        self.biases = np.random.uniform(-4, 4)#เข้าออกเท่ากับขาเข้า\n",
    "\n",
    "\n",
    "        print(f\"shape weigths {self.weigths} shape biases {self.biases}\")\n",
    "        \n",
    "        \n",
    "    def linearRun(self, datas):\n",
    "        \n",
    "        y_predic = datas * self.weigths + self.biases\n",
    "        \n",
    "        return y_predic\n",
    "    \n",
    "    def updataHistory(self, loss, weigths, biases, epoch):\n",
    "        \n",
    "        self.loss_his.append(loss)\n",
    "        self.weigths_his.append(weigths)\n",
    "        self.biases_his.append(biases)\n",
    "        self.epoch_his.append(epoch)\n",
    "    \n",
    "    def lossDerivative(self):\n",
    "        \"\"\"\n",
    "        การหาอนุพัน\n",
    "        Return :\n",
    "            dw: dl /dw , ของค่า mean\n",
    "            db: dl / db\n",
    "        \"\"\"\n",
    "        \n",
    "        dw = np.mean(self.y_predic - self.y) * self.x\n",
    "        db = np.mean(self.y_predic - self.y)\n",
    "        \n",
    "        return dw, db\n",
    "    \n",
    "    def fit(self, data_x, data_y, max_epoch):\n",
    "        \n",
    "        self.x = data_x\n",
    "        self.y = data_y\n",
    "        \n",
    "        p_loss = 0\n",
    "        for epoch in range(max_epoch):\n",
    "            \n",
    "            self.y_predic = self.linearRun(self.x)\n",
    "            \n",
    "            self.loss = LossFunction().meansSquaredError(self.y, self.y_predic)\n",
    "            self.updataHistory(self.loss, self.weigths, self.biases, i)\n",
    "            \n",
    "            self.dw, self.db = self.lossDerivative()\n",
    "            #Updata weigth\n",
    "            self.weigths, self.biases = Optimizer(learning_rate = 0.3,\n",
    "                                                  w = self.weigths,\n",
    "                                                  b = self.biases,\n",
    "                                                  dw = self.dw,\n",
    "                                                  db = self.db).gradientDescent()\n",
    "\n",
    "                    \n",
    "            if np.abs(p_loss - self.loss) < 1e-6:\n",
    "                self.loss = LossFunction().meansSquaredError(self.y, self.y_predic)\n",
    "                self.weigths, self.biases = Optimizer(learning_rate = 0.3,\n",
    "                                                      w = self.weigths,\n",
    "                                                      b = self.biases,\n",
    "                                                      dw = self.dw,\n",
    "                                                      db = self.db).gradientDescent()\n",
    "\n",
    "                \n",
    "            self.loss = LossFunction().meansSquaredError(self.y, self.y_predic)\n",
    "            self.updataHistory(self.loss, self.weigths, self.biases, i)\n",
    "            \n",
    "            p_loss = self.loss\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"epoch {epoch} Loss {self.loss}\")\n",
    "        self.epoch_his.append(i)\n",
    "        self.weigths_his.append(self.weigths)\n",
    "        self.biases_his.append(self.biases)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, learning_rate = None, w = None, b = None, dw = None, db = None):\n",
    "        self.lr = learning_rate\n",
    "        self.weigths = w\n",
    "        self.biases = b\n",
    "        self.dw = dw\n",
    "        self.db = db\n",
    "        \n",
    "    def gradientDescent(self):        \n",
    "        self.weigths = self.weigths - self.lr * self.dw\n",
    "        self.biases = self.biases - self.lr * self.db\n",
    "        \n",
    "        return self.weigths, self.biases\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(object):\n",
    "    \n",
    "    def meansSquaredError(self, y_true, y_predic):\n",
    "        \n",
    "        loss = 0.5 * np.mean((y_predic - y_true)**2)\n",
    "        \n",
    "        return loss\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(219)\n",
    "N = 200\n",
    "a = 4\n",
    "b = -3\n",
    "low = -3.0\n",
    "high = 4.0\n",
    "data_x = np.random.uniform(low=low, high=high, size=N)\n",
    "data_y = np.zeros(N)\n",
    "for i, x in enumerate(data_x):\n",
    "  scale = - (x - low) * (x - high) / 3. + 1.5\n",
    "  data_y[i] = a * x + b + np.random.normal(loc=0.0, scale=scale, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_x, data_y, 'ro')\n",
    "plt.axhline(0, color='black', lw=1)\n",
    "plt.axvline(0, color='black', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data_x, data_y\n",
    "X = np.concatenate((data_x.reshape(N, 1), np.ones(N).reshape(N, 1)), axis=1)\n",
    "Y = data_y.reshape(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, Y, max_epoch = 100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
